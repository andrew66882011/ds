{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "ch06.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrew66882011/ds/blob/master/ch06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56mkRWOswT33",
        "colab_type": "text"
      },
      "source": [
        "*Python Machine Learning 2nd Edition* by [Sebastian Raschka](https://sebastianraschka.com), Packt Publishing Ltd. 2017\n",
        "\n",
        "Code Repository: https://github.com/rasbt/python-machine-learning-book-2nd-edition\n",
        "\n",
        "Code License: [MIT License](https://github.com/rasbt/python-machine-learning-book-2nd-edition/blob/master/LICENSE.txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehl5e1NRwT36",
        "colab_type": "text"
      },
      "source": [
        "# Python Machine Learning - Code Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPlUalY7wT38",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 6 - Learning Best Practices for Model Evaluation and Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjGX4xmUwT3-",
        "colab_type": "text"
      },
      "source": [
        "Note that the optional watermark extension is a small IPython notebook plugin that I developed to make the code reproducible. You can just skip the following line(s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hAQaSs659QM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GDh8ZhvwT3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext watermark\n",
        "%watermark -a \"Andrew Hua\" -u -d -v -p numpy,pandas,matplotlib,sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "zW-v1Y0uwT4K",
        "colab_type": "text"
      },
      "source": [
        "*The use of `watermark` is optional. You can install this IPython extension via \"`pip install watermark`\". For more information, please see: https://github.com/rasbt/watermark.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb_j23LiwT4M",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESC605ynwT4O",
        "colab_type": "text"
      },
      "source": [
        "### Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "178DUdjGwT4Q",
        "colab_type": "text"
      },
      "source": [
        "- [Streamlining workflows with pipelines](#Streamlining-workflows-with-pipelines)\n",
        "  - [Loading the Breast Cancer Wisconsin dataset](#Loading-the-Breast-Cancer-Wisconsin-dataset)\n",
        "  - [Combining transformers and estimators in a pipeline](#Combining-transformers-and-estimators-in-a-pipeline)\n",
        "- [Using k-fold cross-validation to assess model performance](#Using-k-fold-cross-validation-to-assess-model-performance)\n",
        "  - [The holdout method](#The-holdout-method)\n",
        "  - [K-fold cross-validation](#K-fold-cross-validation)\n",
        "- [Debugging algorithms with learning and validation curves](#Debugging-algorithms-with-learning-and-validation-curves)\n",
        "  - [Diagnosing bias and variance problems with learning curves](#Diagnosing-bias-and-variance-problems-with-learning-curves)\n",
        "  - [Addressing overfitting and underfitting with validation curves](#Addressing-overfitting-and-underfitting-with-validation-curves)\n",
        "- [Fine-tuning machine learning models via grid search](#Fine-tuning-machine-learning-models-via-grid-search)\n",
        "  - [Tuning hyperparameters via grid search](#Tuning-hyperparameters-via-grid-search)\n",
        "  - [Algorithm selection with nested cross-validation](#Algorithm-selection-with-nested-cross-validation)\n",
        "- [Looking at different performance evaluation metrics](#Looking-at-different-performance-evaluation-metrics)\n",
        "  - [Reading a confusion matrix](#Reading-a-confusion-matrix)\n",
        "  - [Optimizing the precision and recall of a classification model](#Optimizing-the-precision-and-recall-of-a-classification-model)\n",
        "  - [Plotting a receiver operating characteristic](#Plotting-a-receiver-operating-characteristic)\n",
        "  - [The scoring metrics for multiclass classification](#The-scoring-metrics-for-multiclass-classification)\n",
        "- [Dealing with class imbalance](#Dealing-with-class-imbalance)\n",
        "- [Summary](#Summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T1Bm9xZwT4R",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awQATYhSwT4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n16UoveEwT4a",
        "colab_type": "text"
      },
      "source": [
        "# Streamlining workflows with pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVhUbTP7wT4b",
        "colab_type": "text"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LAbOYlRwT4c",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Breast Cancer Wisconsin dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wMVMAgrwT4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
        "                 'machine-learning-databases'\n",
        "                 '/breast-cancer-wisconsin/wdbc.data', header=None)\n",
        "\n",
        "# if the Breast Cancer dataset is temporarily unavailable from the\n",
        "# UCI machine learning repository, un-comment the following line\n",
        "# of code to load the dataset from a local path:\n",
        "\n",
        "# df_wine = pd.read_csv('wdbc.data', header=None)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xabQeEINwT4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z83S1ggWwT4s",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jmGQCB7wT4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = df.loc[:, 2:].values\n",
        "y = df.loc[:, 1].values\n",
        "print(y[:100])\n",
        "print(type(y))\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "le.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfMbcsNkkPYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y[:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8t0aX4TwT40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le.transform(['M', 'B'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml_OmQqowT47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(X, y, \n",
        "                     test_size=0.20,\n",
        "                     stratify=y,\n",
        "                     random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucz4VfAlwT5B",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS092WQgwT5C",
        "colab_type": "text"
      },
      "source": [
        "## Combining transformers and estimators in a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W87BXJ7FwT5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipe_lr = make_pipeline(StandardScaler(),\n",
        "                        PCA(n_components=2),\n",
        "                        LogisticRegression(random_state=1))\n",
        "\n",
        "pipe_lr.fit(X_train, y_train)\n",
        "y_pred = pipe_lr.predict(X_test)\n",
        "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z6RRYY2wT5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='images/06_01.png', width=500) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVkFYFLRwT5R",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U9npXZywT5S",
        "colab_type": "text"
      },
      "source": [
        "# Using k-fold cross validation to assess model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bGCiR4KwT5T",
        "colab_type": "text"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF7gk64SwT5U",
        "colab_type": "text"
      },
      "source": [
        "## The holdout method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1MulFy_wT5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='images/06_02.png', width=500) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysf-AjzdwT5b",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1txiQGxwT5d",
        "colab_type": "text"
      },
      "source": [
        "## K-fold cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2j-8LcowT5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='images/06_03.png', width=500) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfbpPKQ1wT5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "    \n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10,\n",
        "                        random_state=1).split(X_train, y_train)\n",
        "\n",
        "scores = []\n",
        "for k, (train, test) in enumerate(kfold):\n",
        "    pipe_lr.fit(X_train[train], y_train[train])\n",
        "    score = pipe_lr.score(X_train[test], y_train[test])\n",
        "    scores.append(score)\n",
        "    print('Fold: %2d, Class dist.: %s, Acc: %.3f' % (k+1,\n",
        "          np.bincount(y_train[train]), score))\n",
        "    \n",
        "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkCd8gCEwT5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(estimator=pipe_lr,\n",
        "                         X=X_train,\n",
        "                         y=y_train,\n",
        "                         cv=10,\n",
        "                         n_jobs=1)\n",
        "print('CV accuracy scores: %s' % scores)\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oliFTKXJwT5x",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak1O9N6XwT5y",
        "colab_type": "text"
      },
      "source": [
        "# Debugging algorithms with learning curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXe9c70vwT5z",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyPAWfBYwT50",
        "colab_type": "text"
      },
      "source": [
        "## Diagnosing bias and variance problems with learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5azVPxGwT51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='images/06_04.png', width=600) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5b_LcbmwT58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "\n",
        "pipe_lr = make_pipeline(StandardScaler(),\n",
        "                        LogisticRegression(penalty='l2', random_state=1))\n",
        "\n",
        "train_sizes, train_scores, test_scores =\\\n",
        "                learning_curve(estimator=pipe_lr,\n",
        "                               X=X_train,\n",
        "                               y=y_train,\n",
        "                               train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "                               cv=10,\n",
        "                               n_jobs=1)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.plot(train_sizes, train_mean,\n",
        "         color='blue', marker='o',\n",
        "         markersize=5, label='training accuracy')\n",
        "\n",
        "plt.fill_between(train_sizes,\n",
        "                 train_mean + train_std,\n",
        "                 train_mean - train_std,\n",
        "                 alpha=0.15, color='blue')\n",
        "\n",
        "plt.plot(train_sizes, test_mean,\n",
        "         color='green', linestyle='--',\n",
        "         marker='s', markersize=5,\n",
        "         label='validation accuracy')\n",
        "\n",
        "plt.fill_between(train_sizes,\n",
        "                 test_mean + test_std,\n",
        "                 test_mean - test_std,\n",
        "                 alpha=0.15, color='green')\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('Number of training samples')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim([0.8, 1.03])\n",
        "plt.tight_layout()\n",
        "#plt.savefig('images/06_05.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "264TpU48wT6B",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a87OMvOTwT6C",
        "colab_type": "text"
      },
      "source": [
        "## Addressing over- and underfitting with validation curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axllUxifwT6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "\n",
        "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "train_scores, test_scores = validation_curve(\n",
        "                estimator=pipe_lr, \n",
        "                X=X_train, \n",
        "                y=y_train, \n",
        "                param_name='logisticregression__C', \n",
        "                param_range=param_range,\n",
        "                cv=10)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.plot(param_range, train_mean, \n",
        "         color='blue', marker='o', \n",
        "         markersize=5, label='training accuracy')\n",
        "\n",
        "plt.fill_between(param_range, train_mean + train_std,\n",
        "                 train_mean - train_std, alpha=0.15,\n",
        "                 color='blue')\n",
        "\n",
        "plt.plot(param_range, test_mean, \n",
        "         color='green', linestyle='--', \n",
        "         marker='s', markersize=5, \n",
        "         label='validation accuracy')\n",
        "\n",
        "plt.fill_between(param_range, \n",
        "                 test_mean + test_std,\n",
        "                 test_mean - test_std, \n",
        "                 alpha=0.15, color='green')\n",
        "\n",
        "plt.grid()\n",
        "plt.xscale('log')\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel('Parameter C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.8, 1.0])\n",
        "plt.tight_layout()\n",
        "# plt.savefig('images/06_06.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDk-ij_vwT6I",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsZxebWiwT6J",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tuning machine learning models via grid search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdkeVX-_wT6K",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w_SI7c3wT6L",
        "colab_type": "text"
      },
      "source": [
        "## Tuning hyperparameters via grid search "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsb63rY5wT6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "pipe_svc = make_pipeline(StandardScaler(),\n",
        "                         SVC(random_state=1))\n",
        "\n",
        "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
        "\n",
        "param_grid = [{'svc__C': param_range, \n",
        "               'svc__kernel': ['linear']},\n",
        "              {'svc__C': param_range, \n",
        "               'svc__gamma': param_range, \n",
        "               'svc__kernel': ['rbf']}]\n",
        "\n",
        "gs = GridSearchCV(estimator=pipe_svc, \n",
        "                  param_grid=param_grid, \n",
        "                  scoring='accuracy', \n",
        "                  cv=10,\n",
        "                  n_jobs=-1)\n",
        "gs = gs.fit(X_train, y_train)\n",
        "print(gs.best_score_)\n",
        "print(gs.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJDG_17EwT6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = gs.best_estimator_\n",
        "clf.fit(X_train, y_train)\n",
        "print('Test accuracy: %.3f' % clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiHhaXZfwT6Y",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3QKZbDFwT6Z",
        "colab_type": "text"
      },
      "source": [
        "## Algorithm selection with nested cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5tFWnACwT6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='images/06_07.png', width=500) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHpNktX8wT6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gs = GridSearchCV(estimator=pipe_svc,\n",
        "                  param_grid=param_grid,\n",
        "                  scoring='accuracy',\n",
        "                  cv=2)\n",
        "\n",
        "scores = cross_val_score(gs, X_train, y_train, \n",
        "                         scoring='accuracy', cv=5)\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),\n",
        "                                      np.std(scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33QzSsKmwT6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "gs = GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n",
        "                  param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, None]}],\n",
        "                  scoring='accuracy',\n",
        "                  cv=2)\n",
        "\n",
        "scores = cross_val_score(gs, X_train, y_train, \n",
        "                         scoring='accuracy', cv=5)\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), \n",
        "                                      np.std(scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTgiFHWcwT6p",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUFcZr6-wT6q",
        "colab_type": "text"
      },
      "source": [
        "# Looking at different performance evaluation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhrf0SwCwT6r",
        "colab_type": "text"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eTOEtlCwT6s",
        "colab_type": "text"
      },
      "source": [
        "## Reading a confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC6cEG8rwT6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='images/06_08.png', width=300) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BEKsp3JwT6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "pipe_svc.fit(X_train, y_train)\n",
        "y_pred = pipe_svc.predict(X_test)\n",
        "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "print(confmat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNOCSmlBwT65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
        "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(confmat.shape[0]):\n",
        "    for j in range(confmat.shape[1]):\n",
        "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.tight_layout()\n",
        "#plt.savefig('images/06_09.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPdkA8FVwT6-",
        "colab_type": "text"
      },
      "source": [
        "### Additional Note"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGCueeItwT6_",
        "colab_type": "text"
      },
      "source": [
        "Remember that we previously encoded the class labels so that *malignant* samples are the \"postive\" class (1), and *benign* samples are the \"negative\" class (0):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbTH-WLqwT7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le.transform(['M', 'B'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A34O1eoYwT7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "print(confmat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evk6YqJ3wT7K",
        "colab_type": "text"
      },
      "source": [
        "Next, we printed the confusion matrix like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENgtyezswT7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "print(confmat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PF67tAHwT7Q",
        "colab_type": "text"
      },
      "source": [
        "Note that the (true) class 0 samples that are correctly predicted as class 0 (true negatives) are now in the upper left corner of the matrix (index 0, 0). In order to change the ordering so that the true negatives are in the lower right corner (index 1,1) and the true positves are in the upper left, we can use the `labels` argument like shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdlRyteCwT7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[1, 0])\n",
        "print(confmat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qMaIsATwT7X",
        "colab_type": "text"
      },
      "source": [
        "We conclude:\n",
        "\n",
        "Assuming that class 1 (malignant) is the positive class in this example, our model correctly classified 71 of the samples that belong to class 0 (true negatives) and 40 samples that belong to class 1 (true positives), respectively. However, our model also incorrectly misclassified 1 sample from class 0 as class 1 (false positive), and it predicted that 2 samples are benign although it is a malignant tumor (false negatives)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFXztsq3wT7Y",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9demuXewT7a",
        "colab_type": "text"
      },
      "source": [
        "## Optimizing the precision and recall of a classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KejGCf2gwT7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
        "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
        "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4zR7-X6wT7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "scorer = make_scorer(f1_score, pos_label=0)\n",
        "\n",
        "c_gamma_range = [0.01, 0.1, 1.0, 10.0]\n",
        "\n",
        "param_grid = [{'svc__C': c_gamma_range,\n",
        "               'svc__kernel': ['linear']},\n",
        "              {'svc__C': c_gamma_range,\n",
        "               'svc__gamma': c_gamma_range,\n",
        "               'svc__kernel': ['rbf']}]\n",
        "\n",
        "gs = GridSearchCV(estimator=pipe_svc,\n",
        "                  param_grid=param_grid,\n",
        "                  scoring=scorer,\n",
        "                  cv=10,\n",
        "                  n_jobs=-1)\n",
        "gs = gs.fit(X_train, y_train)\n",
        "print(gs.best_score_)\n",
        "print(gs.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daa3NysUwT7m",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBOroT5jwT7n",
        "colab_type": "text"
      },
      "source": [
        "## Plotting a receiver operating characteristic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExXcenOEwT7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from scipy import interp\n",
        "\n",
        "pipe_lr = make_pipeline(StandardScaler(),\n",
        "                        PCA(n_components=2),\n",
        "                        LogisticRegression(penalty='l2', \n",
        "                                           random_state=1, \n",
        "                                           C=100.0))\n",
        "\n",
        "X_train2 = X_train[:, [4, 14]]\n",
        "    \n",
        "\n",
        "cv = list(StratifiedKFold(n_splits=3, \n",
        "                          random_state=1).split(X_train, y_train))\n",
        "\n",
        "fig = plt.figure(figsize=(7, 5))\n",
        "\n",
        "mean_tpr = 0.0\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "all_tpr = []\n",
        "\n",
        "for i, (train, test) in enumerate(cv):\n",
        "    probas = pipe_lr.fit(X_train2[train],\n",
        "                         y_train[train]).predict_proba(X_train2[test])\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_train[test],\n",
        "                                     probas[:, 1],\n",
        "                                     pos_label=1)\n",
        "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
        "    mean_tpr[0] = 0.0\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr,\n",
        "             tpr,\n",
        "             label='ROC fold %d (area = %0.2f)'\n",
        "                   % (i+1, roc_auc))\n",
        "\n",
        "plt.plot([0, 1],\n",
        "         [0, 1],\n",
        "         linestyle='--',\n",
        "         color=(0.6, 0.6, 0.6),\n",
        "         label='random guessing')\n",
        "\n",
        "mean_tpr /= len(cv)\n",
        "mean_tpr[-1] = 1.0\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
        "         label='mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
        "plt.plot([0, 0, 1],\n",
        "         [0, 1, 1],\n",
        "         linestyle=':',\n",
        "         color='black',\n",
        "         label='perfect performance')\n",
        "\n",
        "plt.xlim([-0.05, 1.05])\n",
        "plt.ylim([-0.05, 1.05])\n",
        "plt.xlabel('false positive rate')\n",
        "plt.ylabel('true positive rate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.savefig('images/06_10.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDZhfc74wT7x",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJXJmVInwT7y",
        "colab_type": "text"
      },
      "source": [
        "## The scoring metrics for multiclass classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXKo81NmwT70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_scorer = make_scorer(score_func=precision_score, \n",
        "                         pos_label=1, \n",
        "                         greater_is_better=True, \n",
        "                         average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1GLMV7YwT76",
        "colab_type": "text"
      },
      "source": [
        "## Dealing with class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4SpEfENwT77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_imb = np.vstack((X[y == 0], X[y == 1][:40]))\n",
        "y_imb = np.hstack((y[y == 0], y[y == 1][:40]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRNYRo1LwT8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.zeros(y_imb.shape[0])\n",
        "np.mean(y_pred == y_imb) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEotcz1YwT8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "print('Number of class 1 samples before:', X_imb[y_imb == 1].shape[0])\n",
        "\n",
        "X_upsampled, y_upsampled = resample(X_imb[y_imb == 1],\n",
        "                                    y_imb[y_imb == 1],\n",
        "                                    replace=True,\n",
        "                                    n_samples=X_imb[y_imb == 0].shape[0],\n",
        "                                    random_state=123)\n",
        "\n",
        "print('Number of class 1 samples after:', X_upsampled.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-fRVebqwT8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_bal = np.vstack((X[y == 0], X_upsampled))\n",
        "y_bal = np.hstack((y[y == 0], y_upsampled))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybYy9D6DwT8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.zeros(y_bal.shape[0])\n",
        "np.mean(y_pred == y_bal) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw8mTlV3wT8W",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kom6ijvbwT8X",
        "colab_type": "text"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM32Aq5dwT8X",
        "colab_type": "text"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhhyFT-8wT8Y",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "Readers may ignore the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx5nVLK-wT8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! python ../.convert_notebook_to_script.py --input ch06.ipynb --output ch06.py"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}